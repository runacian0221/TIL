{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"qbxjGPN05yqn"},"source":["# 1 Word2Vec"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":268,"status":"ok","timestamp":1659279665903,"user":{"displayName":"최재진","userId":"14887547996178540700"},"user_tz":-540},"id":"uZOPysE7617U","vscode":{"languageId":"python"}},"outputs":[],"source":["# 필요한 데이터를 불러와 it_df와 culture_df에 저장한다\n","import pandas as pd\n","it_df = pd.read_csv('./Word Representation_it.csv').dropna()\n","culture_df = pd.read_csv('./Word Representation_culture.csv').dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1659279677045,"user":{"displayName":"최재진","userId":"14887547996178540700"},"user_tz":-540},"id":"6Ok87rnn6102","outputId":"0010651e-db75-486a-b0cf-9c23b8cdd453","vscode":{"languageId":"python"}},"outputs":[],"source":["# word2vec을 하기 위한 전처리\n","# it_df와 culture_df의 컬럼 '1'의 토큰을 리스트 형태로 변경\n","it_token_ls = list(it_df.loc[:,'1']) \n","culture_token_ls = list(culture_df.loc[:,'1'])\n","\n","total_token_ls = it_token_ls + culture_token_ls  # it_df의 리스트와 culture_df의 리스트를 한개로 합침\n","\n","# 리스트의 값을 ','로 분리\n","total_token_ls = [tokens.split(',') for tokens in total_token_ls]\n","print(total_token_ls[0][:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5163,"status":"ok","timestamp":1659279682608,"user":{"displayName":"최재진","userId":"14887547996178540700"},"user_tz":-540},"id":"NHsyT7mo67O3","outputId":"08570635-a270-4a2d-c854-c5986763be92","vscode":{"languageId":"python"}},"outputs":[],"source":["# gensim이라는 패키지에 word2Vec 클래스 사용\n","from gensim.models import Word2Vec\n","word2vec = Word2Vec( sentences = total_token_ls,      # 학습시킬 문장\n","                     vector_size = 10,         # 임베딩된 단어 벡터의 차원 크기\n","                     alpha = 0.025,     # 학습률(Learning rate)\n","                     min_count=2,       # 2번 미만 등장한 단어는 제외\n","                     window = 8,        # 문맥의 크기 (window_size)\n","                     sample = 0.001,    # sub-sampling\n","                     sg = 1,            # 0: CBOW, 1: Skip-gram\n","                     epochs = 10)         # 전체 문장 반복학습 횟수(epoch)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1659279682608,"user":{"displayName":"최재진","userId":"14887547996178540700"},"user_tz":-540},"id":"cWk2rnqV7YMW","outputId":"5503e0cf-57f8-4027-d030-d9e45ca7588a","vscode":{"languageId":"python"}},"outputs":[],"source":["# '인공'의 단어 임베딩 \n","word_embedding = word2vec.wv.__getitem__('인공')\n","print(word_embedding)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1659279682608,"user":{"displayName":"최재진","userId":"14887547996178540700"},"user_tz":-540},"id":"wJPc-Bcg7Zg7","outputId":"1e21940f-d1c7-45ed-ad7c-f55c6f34f2e9","vscode":{"languageId":"python"}},"outputs":[],"source":["# '데이터'의 단어 임베딩 \n","word_embedding = word2vec.wv.__getitem__('데이터')\n","print(word_embedding)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1659279682608,"user":{"displayName":"최재진","userId":"14887547996178540700"},"user_tz":-540},"id":"TZ17uTEO7c1k","outputId":"0cb67d01-bd5e-4f72-8a47-98ecfb712b9d","vscode":{"languageId":"python"}},"outputs":[],"source":["# '인공'과 유사도가 높은 단어\n","word_similar_1 = word2vec.wv.most_similar('인공')\n","print(word_similar_1)\n","\n","#'데이터'와 유사도가 높은 단어\n","word_similar_2 = word2vec.wv.most_similar('데이터')\n","print(word_similar_2)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JwRSC34m5vPs"},"source":["# 2 GloVe\n","\n","- 더이상 지원하지 않음"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7000,"status":"ok","timestamp":1659279775424,"user":{"displayName":"최재진","userId":"14887547996178540700"},"user_tz":-540},"id":"v9wo1mA02cHz","outputId":"b4538f31-7659-4913-a077-fb2b5e604f0a","vscode":{"languageId":"python"}},"outputs":[],"source":["# !pip install glove_python_binary\n","\n","# from glove import Corpus, Glove\n","\n","# corpus = Corpus() \n","# corpus.fit(total_token_ls, window=5)\n","# # 훈련 데이터로부터 GloVe에서 사용할 동시 등장 행렬 생성\n","\n","# glove = Glove(no_components=100, learning_rate=0.05)\n","# glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n","# glove.add_dictionary(corpus.dictionary)\n","# # 학습에 이용할 쓰레드의 개수는 4로 설정, 에포크는 20.\n","\n","# glove.most_similar(\"인공\")\n","# glove.most_similar(\"지능\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dMVqD431-HS4"},"source":["# 3 FastText"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5661,"status":"ok","timestamp":1659279837989,"user":{"displayName":"최재진","userId":"14887547996178540700"},"user_tz":-540},"id":"lfJ-l1Po-IhS","outputId":"93da5f54-254c-413f-9d08-b9305a748c2b","vscode":{"languageId":"python"}},"outputs":[],"source":["from gensim.models.word2vec import Text8Corpus\n","from gensim.models import FastText\n","\n","# FastText 모델생성\n","ft_model = FastText(total_token_ls,  \n","                      vector_size=10,                 # 임베딩된 단어 벡터의 차원 크기\n","                      window=8,                 # 문맥의 크기(window_size)\n","                      min_count=2,            # 2번 미만 등장한 단어는 제외\n","                      alpha = 0.025,                    # 학습률(Learning rate)\n","                      sg = 1,                             # 0: CBOW, 1: Skip-gram\n","                      epochs = 10,              # 전체 문장 반복학습 횟수(epoch)\n","                      min_n=3, max_n=6)            # 최소, 최대 N-gram 수   "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1659279837990,"user":{"displayName":"최재진","userId":"14887547996178540700"},"user_tz":-540},"id":"SOvGNGjG-LAW","outputId":"0c9bc9c8-c949-420d-eb6f-da5f5966f4f4","vscode":{"languageId":"python"}},"outputs":[],"source":["# Getting most similar vectors\n","print(ft_model.wv.most_similar('인공'))\n","\n","# Getting most similar vectors\n","print(ft_model.wv.most_similar('안공지능'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1659279837990,"user":{"displayName":"최재진","userId":"14887547996178540700"},"user_tz":-540},"id":"D0gMrWOj_5de","outputId":"1d83318e-3faf-41fa-9cf0-5bb90cb9761d","vscode":{"languageId":"python"}},"outputs":[],"source":["ft_model.wv['너지']"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"0_Word Representation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
