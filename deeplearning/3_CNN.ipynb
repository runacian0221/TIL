{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"o9THKomKIxvC"},"source":["# 1 CNN"]},{"cell_type":"markdown","metadata":{"id":"XVu3zcxEOq6a"},"source":["#1 CNN (MNIST)"]},{"cell_type":"markdown","metadata":{"id":"fG9HYp3-I5sg"},"source":["https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/tutorials/images/cnn.ipynb?hl=ko#scrollTo=jKgyC5K_4O0d"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jRFxccghyMVo"},"source":["### 1) MNIST 데이터셋 다운로드하고 준비하기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"elapsed":5231,"status":"ok","timestamp":1598230303427,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"JWoEqyMuXFF4","outputId":"c0076059-cd66-4b3c-b9ee-1328294b1416","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 1s 0us/step\n"]}],"source":["#!pip install tensorflow-gpu==2.0.0-rc1\n","import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","\n","(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n","\n","train_images = train_images.reshape((60000, 28, 28, 1)) #데이터 건수, 이미지 높이, 이미지 너비, 컬러 채널\n","test_images = test_images.reshape((10000, 28, 28, 1)) #데이터 건수, 이미지 높이, 이미지 너비, 컬러 채널\n","\n","# 픽셀 값을 0~1 사이로 정규화합니다.\n","train_images, test_images = train_images / 255.0, test_images / 255.0"]},{"cell_type":"markdown","metadata":{"id":"Oewp-wYg31t9"},"source":["### 2) CNN 만들기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"elapsed":10990,"status":"ok","timestamp":1598230309192,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"L9YmGQBQPrdn","outputId":"cef84974-0340-4a15-a203-0cfe3b831b81","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n","_________________________________________________________________\n","flatten (Flatten)            (None, 576)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 64)                36928     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 93,322\n","Trainable params: 93,322\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model = models.Sequential()\n","# 특징 추출 (Feature Extraction)\n","model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) # 32 * 3 * 3 + 32 = 320\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu')) # 32 * 64 * 3 * 3 + 64 = 18496\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu')) # 64 * 64 * 3 * 3 + 64 = 36928\n","\n","# 분류 (Classification)\n","model.add(layers.Flatten()) # 576개 벡터로 Flatten\n","model.add(layers.Dense(64, activation='relu')) # 576 * 64 + 64 = 36928\n","model.add(layers.Dense(10, activation='softmax')) # 64 * 10 + 10 = 650\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"P3odqfHP4M67"},"source":["### 3) 모델 컴파일과 훈련하기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":43503,"status":"ok","timestamp":1598230341707,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"MdDzI75PUXrG","outputId":"202ee9f9-a78a-4604-c0b7-8901e9b18ce1","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.1388 - accuracy: 0.9582\n","Epoch 2/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0445 - accuracy: 0.9860\n","Epoch 3/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0323 - accuracy: 0.9895\n","Epoch 4/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0250 - accuracy: 0.9921\n","Epoch 5/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0192 - accuracy: 0.9941\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f9d2a207d30>"]},"execution_count":3,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(train_images, train_labels, epochs=5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jKgyC5K_4O0d"},"source":["### 4) 모델 평가"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"elapsed":44541,"status":"ok","timestamp":1598230342747,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"gtyDF0MKUcM7","outputId":"c1a214ab-45bd-4aab-85a5-6562f49e990f","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["313/313 - 1s - loss: 0.0292 - accuracy: 0.9906\n","0.9905999898910522\n"]}],"source":["test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n","print(test_acc)"]},{"cell_type":"markdown","metadata":{"id":"IUJN6pqEOaIy"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"1bvGKMdSOVyC"},"source":["# 2 CNN for Sentence Classification"]},{"cell_type":"markdown","metadata":{"id":"iWr3mGouyFmQ"},"source":["https://www.aclweb.org/anthology/D14-1181/"]},{"cell_type":"markdown","metadata":{"id":"ZUy7jArNyMZV"},"source":["<img src=\"http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-8.03.47-AM-1024x413.png\" />"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PCJC8o7KfTNN"},"source":["## 1) 네이버 영화 리뷰 다운로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ac0ZajKK2Ph_","vscode":{"languageId":"python"}},"outputs":[],"source":["!pip install tensorflow-gpu "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"elapsed":5563,"status":"ok","timestamp":1598233290434,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"lNriA4DKNVgQ","outputId":"2d8665b0-3952-4dd2-8dac-e71d06570406","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["--2020-08-24 01:41:27--  https://github.com/e9t/nsmc/raw/master/ratings.txt\n","Resolving github.com (github.com)... 140.82.114.4\n","Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt [following]\n","--2020-08-24 01:41:27--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19515078 (19M) [text/plain]\n","Saving to: ‘ratings.txt.1’\n","\n","ratings.txt.1       100%[===================>]  18.61M  36.2MB/s    in 0.5s    \n","\n","2020-08-24 01:41:28 (36.2 MB/s) - ‘ratings.txt.1’ saved [19515078/19515078]\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8112052</td>\n","      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8132799</td>\n","      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4655635</td>\n","      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9251303</td>\n","      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10067386</td>\n","      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id                                           document  label\n","0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n","1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n","2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n","3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n","4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"]},"execution_count":9,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# 네이버 영화 리뷰 다운로드\n","!wget https://github.com/e9t/nsmc/raw/master/ratings.txt\n","\n","import pandas as pd\n","import numpy as np\n","df = pd.read_csv(\"./ratings.txt\",sep='\\t').dropna()\n","df.head(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-rfddH3RfXLe"},"source":["## 2) 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPgNyyoXkB6f","vscode":{"languageId":"python"}},"outputs":[],"source":["import json\n","from tensorflow.keras import preprocessing\n","\n","def preprocess(x, y, padding_size = 128, oov_token=\"<UNK>\", vocab_file = \"vocab.json\", train_ratio=0.7) :  \n","  preprocessor = preprocessing.text.Tokenizer(oov_token=oov_token) #토큰화\n","  preprocessor.fit_on_texts(x)\n","  x = preprocessor.texts_to_sequences(x) #시퀀스로 변환\n","  vocab = preprocessor.word_index #단어:인덱스 dictionary\n","  json.dump(vocab, open(vocab_file, 'w'), ensure_ascii=False)\n","  x = preprocessing.sequence.pad_sequences(x, maxlen=padding_size, padding='post', truncating='post')\n","\n","  index = int(len(x)*train_ratio)\n","\n","  return x[:index], y[:index], x[index:], y[index:], vocab\n","\n","x_train, y_train, x_test, y_test, vocab = preprocess(df[\"document\"].tolist(), df[\"label\"].tolist())"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vzkqF56qfavV"},"source":["## 3) 모델 정의"]},{"cell_type":"markdown","metadata":{"id":"PrSyfNITYP6U"},"source":["<img src=\"https://miro.medium.com/max/770/0*wigQtmJiv0bddwPI.\" width=\"500\" />"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":629},"executionInfo":{"elapsed":14143,"status":"ok","timestamp":1598233300166,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"sx6gRwN6Oczp","outputId":"56f96541-a9de-4526-a457-914df8a607c7","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"functional_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_data (InputLayer)         [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 128, 512)     188943872   input_data[0][0]                 \n","__________________________________________________________________________________________________\n","add_channel (Reshape)           (None, 128, 512, 1)  0           embedding[0][0]                  \n","__________________________________________________________________________________________________\n","convolution_3 (Conv2D)          (None, 126, 1, 128)  196736      add_channel[0][0]                \n","__________________________________________________________________________________________________\n","convolution_4 (Conv2D)          (None, 125, 1, 128)  262272      add_channel[0][0]                \n","__________________________________________________________________________________________________\n","convolution_5 (Conv2D)          (None, 124, 1, 128)  327808      add_channel[0][0]                \n","__________________________________________________________________________________________________\n","max_pooling_3 (MaxPooling2D)    (None, 1, 1, 128)    0           convolution_3[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling_4 (MaxPooling2D)    (None, 1, 1, 128)    0           convolution_4[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling_5 (MaxPooling2D)    (None, 1, 1, 128)    0           convolution_5[0][0]              \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 1, 1, 384)    0           max_pooling_3[0][0]              \n","                                                                 max_pooling_4[0][0]              \n","                                                                 max_pooling_5[0][0]              \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 384)          0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 384)          0           flatten[0][0]                    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 2)            770         dropout[0][0]                    \n","==================================================================================================\n","Total params: 189,731,458\n","Trainable params: 189,731,458\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["from tensorflow import keras\n","\n","def CNNforText( num_classes,  #클래스 갯수\n","          vocab_size,\n","          embed_size = 512, #단어 임베딩 사이즈                 \n","          filter_sizes = [3,4,5],\n","          regularizers_lambda = 0.01, #L2 regulation parameter\n","          dropout =  0.5,\n","          feature_size = 128, #문장 시퀀스 길이\n","          num_filters = 128 #필터 개수 (필터사이즈와 같음). mhlee 하나로 통일하자\n",") :\n","          \n","\n","  inputs = keras.Input(shape=(feature_size,), name='input_data')\n","  embed_initer = keras.initializers.RandomUniform(minval=-1, maxval=1)\n","  #sequence 임베딩\n","  embed = keras.layers.Embedding(vocab_size, embed_size,\n","                                  embeddings_initializer=embed_initer,\n","                                  input_length=feature_size,\n","                                  name='embedding')(inputs)\n","                                  \n","  embed = keras.layers.Reshape((feature_size, embed_size, 1), name='add_channel')(embed)\n","\n","  pool_outputs = []\n","\n","  #filter 별로 모델 구성\n","  for filter_size in filter_sizes :\n","    #convolution\n","    filter_shape = (filter_size, embed_size)\n","    conv = keras.layers.Conv2D(num_filters, filter_shape, strides=(1, 1), padding='valid',\n","                                data_format='channels_last', activation='relu',\n","                                kernel_initializer='glorot_normal',\n","                                bias_initializer=keras.initializers.constant(0.1),\n","                                name='convolution_{:d}'.format(filter_size))(embed)\n","    #max pooling\n","    max_pool_shape = (feature_size - filter_size + 1, 1)\n","    pool = keras.layers.MaxPool2D(pool_size=max_pool_shape,\n","                                  strides=(1, 1), padding='valid',\n","                                  data_format='channels_last',\n","                                  name='max_pooling_{:d}'.format(filter_size))(conv)\n","    pool_outputs.append(pool)\n","\n","  pool_outputs = keras.layers.concatenate(pool_outputs, axis=-1, name='concatenate')\n","  pool_outputs = keras.layers.Flatten(data_format='channels_last', name='flatten')(pool_outputs)\n","  pool_outputs = keras.layers.Dropout(dropout, name='dropout')(pool_outputs)\n","\n","  outputs = keras.layers.Dense(num_classes, activation='softmax',\n","                                kernel_initializer='glorot_normal',\n","                                bias_initializer=keras.initializers.constant(0.1),\n","                                kernel_regularizer=keras.regularizers.l2(regularizers_lambda),\n","                                bias_regularizer=keras.regularizers.l2(regularizers_lambda),\n","                                name='dense')(pool_outputs)\n","  model = keras.Model(inputs=inputs, outputs=outputs)\n","  model.summary()\n","  return model, num_classes\n","\n","model, num_classes = CNNforText(len(np.unique(y_train)), len(vocab))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HLYN-56TfrPS"},"source":["## 4) 학습\n","\n","- 상당한 RAM을 소모하므로, size를 전체적으로 줄여서 학습시킬 것"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"executionInfo":{"elapsed":656412,"status":"ok","timestamp":1598233943461,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"BdwIPx2rdEmA","outputId":"33da5f82-e7ff-4fa3-d554-a329556ad0e7","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","15/15 [==============================] - 70s 5s/step - loss: 0.0934 - accuracy: 0.9558 - val_loss: 0.0412 - val_accuracy: 1.0000\n","Epoch 2/10\n","15/15 [==============================] - 61s 4s/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 1.0000\n","Epoch 3/10\n","15/15 [==============================] - 52s 3s/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 1.0000\n","Epoch 4/10\n","15/15 [==============================] - 56s 4s/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 1.0000\n","Epoch 5/10\n","15/15 [==============================] - 59s 4s/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 1.0000\n","Epoch 6/10\n","15/15 [==============================] - 55s 4s/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000\n","Epoch 7/10\n","15/15 [==============================] - 53s 4s/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 1.0000\n","Epoch 8/10\n","15/15 [==============================] - 57s 4s/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n","Epoch 9/10\n","15/15 [==============================] - 54s 4s/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000\n","Epoch 10/10\n","15/15 [==============================] - 54s 4s/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 1.0000\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","INFO:tensorflow:Assets written to: model/assets\n","{'loss': [0.09340319782495499, 0.04068756848573685, 0.03932049125432968, 0.03766585886478424, 0.035830628126859665, 0.033882103860378265, 0.03186929598450661, 0.02983052097260952, 0.02779657207429409, 0.025792302563786507], 'accuracy': [0.9557894468307495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.04119666665792465, 0.040010761469602585, 0.038466326892375946, 0.03670129179954529, 0.03479591757059097, 0.03280576318502426, 0.03077336959540844, 0.028732657432556152, 0.026711028069257736, 0.02473054639995098], 'val_accuracy': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n"]}],"source":["import os\n","import time\n","import tensorflow as tf\n","\n","def train(model, x_train, y_train, num_classes\n","          , batch_size = 64, epochs = 1, fraction_validation = 0.05, results_dir = \"./result/\", save_path = \"model\") :\n","  timestamp = time.strftime(\"%Y-%m-%d-%H-%M\", time.localtime(time.time()))\n","  path = os.path.join(results_dir, timestamp)\n","  if not os.path.exists(path) :    \n","    path_log = os.path.join(path, 'log/')\n","    os.makedirs(path_log)\n","\n","  model.compile(tf.optimizers.Adam(), loss='categorical_crossentropy',metrics=['accuracy'])\n","  #모델 구조 이미지 파일로 저장\n","  keras.utils.plot_model(model, show_shapes=True, to_file=os.path.join(path, \"model.jpg\"))\n","  y_train = tf.one_hot(y_train, num_classes)\n","  tb_callback = keras.callbacks.TensorBoard(path_log,\n","                                            histogram_freq=0.1, write_graph=True,\n","                                            write_images=True,\n","                                            embeddings_freq=0.5, update_freq='batch')\n","\n","  history = model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=epochs,\n","                                callbacks=[tb_callback], validation_split=fraction_validation, shuffle=True)\n","  \n","  #모델 저장\n","  keras.models.save_model(model, save_path)\n","  print(history.history)\n","\n","  return model, path_log\n","\n","model, path_log = train(model, x_train[:1000], y_train[:1000], num_classes, epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MxKDmHsEwLmH","vscode":{"languageId":"python"}},"outputs":[],"source":["%load_ext tensorboard\n","%tensorboard --logdir {path_log}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1brKOSoNpqE8"},"source":["## 5) 평가"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SuKxvAvMps3J","vscode":{"languageId":"python"}},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n","\n","def test(model, x_test, y_test, num_classes):\n","  y_pred_one_hot = model.predict(x=x_test, batch_size=1, verbose=1)\n","  y_pred = tf.math.argmax(y_pred_one_hot, axis=1)\n","\n","  print('\\nTest accuracy: {}\\n'.format(accuracy_score(y_test, y_pred)))\n","  print('Classification report:')\n","  target_names = ['class {:d}'.format(i) for i in np.arange(num_classes)]\n","  print(classification_report(y_test, y_pred, target_names=target_names, digits=4))\n","\n","test(model, x_test[:50000], y_test[:50000], num_classes)"]},{"cell_type":"markdown","metadata":{"id":"2MkvvzeGZhGq"},"source":["# 3 CNN for Sentence Classification (FastText)"]},{"cell_type":"markdown","metadata":{"id":"OvAR1X4-ZhGr"},"source":["https://www.aclweb.org/anthology/D14-1181/"]},{"cell_type":"markdown","metadata":{"id":"eXkI5fglZhGr"},"source":["<img src=\"http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-8.03.47-AM-1024x413.png\" />"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"osSwreEvZhGr"},"source":["## 1) 네이버 영화 리뷰 다운로드"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":598},"executionInfo":{"elapsed":8145,"status":"ok","timestamp":1598312410716,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"bPPr4dwafjpH","outputId":"ad74fc92-a8b8-49e5-b07a-255db74530ce","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n","\u001b[?25hCollecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 63.5MB/s \n","\u001b[?25hCollecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 13.2MB/s \n","\u001b[?25hCollecting tweepy>=3.7.0\n","  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, beautifulsoup4, tweepy, colorama, konlpy\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n"]}],"source":["!pip install konlpy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496},"executionInfo":{"elapsed":5964,"status":"ok","timestamp":1598312412812,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"zFKCeheVZhGt","outputId":"791f2d79-2009-464c-e099-4a58da01a25b","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["--2020-08-24 23:40:09--  https://github.com/e9t/nsmc/raw/master/ratings.txt\n","Resolving github.com (github.com)... 140.82.118.4\n","Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt [following]\n","--2020-08-24 23:40:10--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19515078 (19M) [text/plain]\n","Saving to: ‘ratings.txt’\n","\n","ratings.txt         100%[===================>]  18.61M  --.-KB/s    in 0.1s    \n","\n","2020-08-24 23:40:11 (141 MB/s) - ‘ratings.txt’ saved [19515078/19515078]\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8112052</td>\n","      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8132799</td>\n","      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4655635</td>\n","      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9251303</td>\n","      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10067386</td>\n","      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id                                           document  label\n","0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n","1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n","2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n","3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n","4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"]},"execution_count":2,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# 네이버 영화 리뷰 다운로드\n","!wget https://github.com/e9t/nsmc/raw/master/ratings.txt\n","\n","import pandas as pd\n","import numpy as np\n","df = pd.read_csv(\"./ratings.txt\",sep='\\t').dropna()\n","df.head(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uw562eCtZhGv"},"source":["## 2) 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":479},"executionInfo":{"elapsed":86979,"status":"ok","timestamp":1598312494611,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"GCsOsHHFnxMp","outputId":"eb2d82a2-43bd-4edb-d124-2d73147950d2","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["--2020-08-24 23:40:11--  https://www.dropbox.com/s/stt4y0zcp2c0iyb/ko.tar.gz\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/stt4y0zcp2c0iyb/ko.tar.gz [following]\n","--2020-08-24 23:40:12--  https://www.dropbox.com/s/raw/stt4y0zcp2c0iyb/ko.tar.gz\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uccc6446f8516e88d64ecc9fe0eb.dl.dropboxusercontent.com/cd/0/inline/A-FcNH-78QhfzjCOJRS6mcWjZbTDw2MSORgS-C1ZNoo-O_4gNFsFBuFeuOJxNXCI6L1eiUCqdzULD_3na5X5z2fIAw0gOEYkkxqN9ThwWpg5XQ/file# [following]\n","--2020-08-24 23:40:12--  https://uccc6446f8516e88d64ecc9fe0eb.dl.dropboxusercontent.com/cd/0/inline/A-FcNH-78QhfzjCOJRS6mcWjZbTDw2MSORgS-C1ZNoo-O_4gNFsFBuFeuOJxNXCI6L1eiUCqdzULD_3na5X5z2fIAw0gOEYkkxqN9ThwWpg5XQ/file\n","Resolving uccc6446f8516e88d64ecc9fe0eb.dl.dropboxusercontent.com (uccc6446f8516e88d64ecc9fe0eb.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6022:15::a27d:420f\n","Connecting to uccc6446f8516e88d64ecc9fe0eb.dl.dropboxusercontent.com (uccc6446f8516e88d64ecc9fe0eb.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/A-EZDvEkHtGUwfrfQW6adhJ_sULK4FHQJ1ijj4hM5aCTb42_SJIfUL95ToRDM811kFc8Th6zoK9GdbfcIu_1pwv3eJE3BpcmW44iTfQoUe4iNVuVUpBXJ9Rx6rkrjw6-pF7wCEFfeurvWbRyF1GBppkVu0DWm2EVGOPm3o73ULxycCK1kTdAjZ7_pvGyfn_HJyclO4SjGhtrPwTKaKFJexzIijx3qZWe1Tat0eeUltSeRVr-jRVbgM0ebccOfwY0MpibVKHzCgTDW6AGGxsm8bLq_3okTdFDpqZyyR2z3nWb34e3bedJns-Ief-SxroHdypI_St31zq5ygCG11y_RF2K/file [following]\n","--2020-08-24 23:40:13--  https://uccc6446f8516e88d64ecc9fe0eb.dl.dropboxusercontent.com/cd/0/inline2/A-EZDvEkHtGUwfrfQW6adhJ_sULK4FHQJ1ijj4hM5aCTb42_SJIfUL95ToRDM811kFc8Th6zoK9GdbfcIu_1pwv3eJE3BpcmW44iTfQoUe4iNVuVUpBXJ9Rx6rkrjw6-pF7wCEFfeurvWbRyF1GBppkVu0DWm2EVGOPm3o73ULxycCK1kTdAjZ7_pvGyfn_HJyclO4SjGhtrPwTKaKFJexzIijx3qZWe1Tat0eeUltSeRVr-jRVbgM0ebccOfwY0MpibVKHzCgTDW6AGGxsm8bLq_3okTdFDpqZyyR2z3nWb34e3bedJns-Ief-SxroHdypI_St31zq5ygCG11y_RF2K/file\n","Reusing existing connection to uccc6446f8516e88d64ecc9fe0eb.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1543812655 (1.4G) [application/octet-stream]\n","Saving to: ‘ko.tar.gz’\n","\n","ko.tar.gz           100%[===================>]   1.44G  25.3MB/s    in 60s     \n","\n","2020-08-24 23:41:14 (24.5 MB/s) - ‘ko.tar.gz’ saved [1543812655/1543812655]\n","\n","ko.bin\n","ko.vec\n"]}],"source":["!wget https://www.dropbox.com/s/stt4y0zcp2c0iyb/ko.tar.gz\n","!tar xvzf ko.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_DM0Hj_sZoz2","vscode":{"languageId":"python"}},"outputs":[],"source":["import numpy as np\n","\n","def load_dic(dic_file) :\n","  embeddings_index = dict()\n","  f = open(dic_file)\n","  for i, line in enumerate(f):\n","    if i == 0 : continue\n","    try :\n","      values = line.split()\n","      word = values[0]\n","      coefs = np.asarray(values[1:], dtype='float32')\n","      embeddings_index[word] = coefs\n","    except :\n","      print(i)\n","      print(values)\n","  f.close()\n","\n","  return embeddings_index\n","\n","embeddings_index = load_dic('ko.vec')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qax1meUQZhGv","vscode":{"languageId":"python"}},"outputs":[],"source":["import json\n","from tensorflow.keras import preprocessing\n","import konlpy \n","from konlpy.tag import Okt \n","\n","def preprocess(x, y, padding_size = 128, oov_token=\"<UNK>\", vocab_file = \"vocab.json\", train_ratio=0.7) :  \n","  okt = Okt()\n","  X_test = [] \n","\n","  for sentence in x: \n","    stopwords = ['의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', '하다']\n","\n","    temp_X = [] \n","    temp_X = okt.morphs(sentence, stem=True) # 토큰화 \n","    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거 \n","    X_test.append(temp_X)\n","\n","  preprocessor = preprocessing.text.Tokenizer(oov_token=oov_token) #토큰화\n","  preprocessor.fit_on_texts(X_test)\n","  x = preprocessor.texts_to_sequences(x) #시퀀스로 변환\n","  vocab = preprocessor.word_index #단어:인덱스 dictionary\n","  json.dump(vocab, open(vocab_file, 'w'), ensure_ascii=False)\n","  x = preprocessing.sequence.pad_sequences(x, maxlen=padding_size, padding='post', truncating='post')\n","\n","  index = int(len(x)*train_ratio)\n","\n","  return x[:index], y[:index], x[index:], y[index:], vocab\n","\n","x_train, y_train, x_test, y_test, vocab = preprocess(df[\"document\"].tolist(), df[\"label\"].tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FzOmEcJEaJ2O","vscode":{"languageId":"python"}},"outputs":[],"source":["def gen_embedding_matrix(vocab, embeddings_index, embedding_size) :\n","  vocabulary_size = len(vocab)\n","\n","  embedding_matrix = np.zeros((vocabulary_size, embedding_size))\n","  for word, index in vocab.items():\n","      if index > vocabulary_size - 1:\n","          break\n","      else:\n","          embedding_vector = embeddings_index.get(word)\n","          if embedding_vector is not None:\n","              embedding_matrix[index] = embedding_vector\n","  return embedding_matrix\n","\n","embedding_matrix = gen_embedding_matrix(vocab, embeddings_index, embedding_size=200)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yiFMPDYrZhGx"},"source":["## 3) 모델 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":629},"executionInfo":{"elapsed":8379,"status":"ok","timestamp":1598314847536,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"WPLd0a62ZhGy","outputId":"dc3620e7-3c2d-4212-fbd2-e0a10375d460","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_data (InputLayer)         [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 128, 200)     11341200    input_data[0][0]                 \n","__________________________________________________________________________________________________\n","add_channel (Reshape)           (None, 128, 200, 1)  0           embedding[0][0]                  \n","__________________________________________________________________________________________________\n","convolution_3 (Conv2D)          (None, 126, 1, 128)  76928       add_channel[0][0]                \n","__________________________________________________________________________________________________\n","convolution_4 (Conv2D)          (None, 125, 1, 128)  102528      add_channel[0][0]                \n","__________________________________________________________________________________________________\n","convolution_5 (Conv2D)          (None, 124, 1, 128)  128128      add_channel[0][0]                \n","__________________________________________________________________________________________________\n","max_pooling_3 (MaxPooling2D)    (None, 1, 1, 128)    0           convolution_3[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling_4 (MaxPooling2D)    (None, 1, 1, 128)    0           convolution_4[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling_5 (MaxPooling2D)    (None, 1, 1, 128)    0           convolution_5[0][0]              \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 1, 1, 384)    0           max_pooling_3[0][0]              \n","                                                                 max_pooling_4[0][0]              \n","                                                                 max_pooling_5[0][0]              \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 384)          0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 384)          0           flatten[0][0]                    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 2)            770         dropout[0][0]                    \n","==================================================================================================\n","Total params: 11,649,554\n","Trainable params: 308,354\n","Non-trainable params: 11,341,200\n","__________________________________________________________________________________________________\n"]}],"source":["from tensorflow import keras\n","\n","def CNNforText( num_classes,  #클래스 갯수\n","          vocab_size,\n","          embedding_matrix,           \n","          filter_sizes = [3, 4, 5],\n","          regularizers_lambda = 0.01, #L2 regulation parameter\n","          dropout =  0.5,\n","          feature_size = 128, #문장 시퀀스 길이\n","          num_filters = 128 #필터 개수 (필터사이즈와 같음). \n",") :\n","\n","  inputs = keras.Input(shape=(feature_size,), name='input_data')   \n","  embed_size = embedding_matrix.shape[1]\n","  embed = keras.layers.Embedding(vocab_size, embed_size, input_length=feature_size, weights=[embedding_matrix], trainable=False, name='embedding')(inputs)\n","  embed = keras.layers.Reshape((feature_size, embed_size, 1), name='add_channel')(embed)\n","  pool_outputs = []\n","\n","  #filter 별로 모델 구성\n","  for filter_size in filter_sizes :\n","    #convolution\n","    filter_shape = (filter_size, embed_size)\n","    conv = keras.layers.Conv2D(num_filters, filter_shape, strides=(1, 1), padding='valid',\n","                                data_format='channels_last', activation='relu',\n","                                kernel_initializer='glorot_normal',\n","                                bias_initializer=keras.initializers.constant(0.1),\n","                                name='convolution_{:d}'.format(filter_size))(embed)\n","    #max pooling\n","    max_pool_shape = (feature_size - filter_size + 1, 1)\n","    pool = keras.layers.MaxPool2D(pool_size=max_pool_shape,\n","                                  strides=(1, 1), padding='valid',\n","                                  data_format='channels_last',\n","                                  name='max_pooling_{:d}'.format(filter_size))(conv)\n","    pool_outputs.append(pool)\n","\n","  pool_outputs = keras.layers.concatenate(pool_outputs, axis=-1, name='concatenate')\n","  pool_outputs = keras.layers.Flatten(data_format='channels_last', name='flatten')(pool_outputs)\n","  pool_outputs = keras.layers.Dropout(dropout, name='dropout')(pool_outputs)\n","\n","  outputs = keras.layers.Dense(num_classes, activation='softmax',\n","                                kernel_initializer='glorot_normal',\n","                                bias_initializer=keras.initializers.constant(0.1),\n","                                kernel_regularizer=keras.regularizers.l2(regularizers_lambda),\n","                                bias_regularizer=keras.regularizers.l2(regularizers_lambda),\n","                                name='dense')(pool_outputs)\n","  model = keras.Model(inputs=inputs, outputs=outputs)\n","  model.summary()\n","  return model, num_classes\n","\n","model, num_classes = CNNforText(len(np.unique(y_train)), len(vocab), embedding_matrix)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LNHWPa5eZhG0"},"source":["## 4) 학습"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258},"executionInfo":{"elapsed":33557,"status":"ok","timestamp":1598314881100,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"AHgykwIqZhG0","outputId":"a82e3f34-68c9-45ab-a71d-ede9e65fd33f","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\r   1/2079 [..............................] - ETA: 1s - loss: 0.8216 - accuracy: 0.2656WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n","Instructions for updating:\n","use `tf.profiler.experimental.stop` instead.\n","   2/2079 [..............................] - ETA: 1:00 - loss: 0.7583 - accuracy: 0.4219WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0146s vs `on_train_batch_end` time: 0.0424s). Check your callbacks.\n","2079/2079 [==============================] - 22s 11ms/step - loss: 0.5261 - accuracy: 0.7651 - val_loss: 1.2333 - val_accuracy: 0.1396\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","INFO:tensorflow:Assets written to: model/assets\n","{'loss': [0.5261073112487793], 'accuracy': [0.7651247382164001], 'val_loss': [1.2332805395126343], 'val_accuracy': [0.1395714282989502]}\n"]}],"source":["import os\n","import time\n","import tensorflow as tf\n","\n","def train(model, x_train, y_train, num_classes\n","          , batch_size = 64, epochs = 1, fraction_validation = 0.05, results_dir = \"./result/\", save_path = \"model\") :\n","  timestamp = time.strftime(\"%Y-%m-%d-%H-%M\", time.localtime(time.time()))\n","  path = os.path.join(results_dir, timestamp)\n","  if not os.path.exists(path) :    \n","    path_log = os.path.join(path, 'log/')\n","    os.makedirs(path_log)\n","\n","  model.compile(tf.optimizers.Adam(), loss='categorical_crossentropy',metrics=['accuracy'])\n","  #모델 구조 이미지 파일로 저장\n","  keras.utils.plot_model(model, show_shapes=True, to_file=os.path.join(path, \"model.jpg\"))\n","  y_train = tf.one_hot(y_train, num_classes)\n","  tb_callback = keras.callbacks.TensorBoard(path_log,\n","                                            histogram_freq=0.1, write_graph=True,\n","                                            write_images=True,\n","                                            embeddings_freq=0.5, update_freq='batch')\n","\n","  history = model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=epochs,\n","                                callbacks=[tb_callback], validation_split=fraction_validation, shuffle=True)\n","  \n","  #모델 저장\n","  keras.models.save_model(model, save_path)\n","  print(history.history)\n","\n","  return model, path_log\n","\n","model, path_log = train(model, x_train, y_train, num_classes, epochs=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3RIC-1AuZhG1","vscode":{"languageId":"python"}},"outputs":[],"source":["%load_ext tensorboard\n","%tensorboard --logdir {path_log}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TkoquXtYZhG2"},"source":["## 5) 평가"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d0qXQ7qOZhG3","vscode":{"languageId":"python"}},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n","\n","def test(model, x_test, y_test, num_classes):\n","  y_pred_one_hot = model.predict(x=x_test, batch_size=1, verbose=1)\n","  y_pred = tf.math.argmax(y_pred_one_hot, axis=1)\n","\n","  print('\\nTest accuracy: {}\\n'.format(accuracy_score(y_test, y_pred)))\n","  print('Classification report:')\n","  target_names = ['class {:d}'.format(i) for i in np.arange(num_classes)]\n","  print(classification_report(y_test, y_pred, target_names=target_names, digits=4))\n","\n","test(model, x_test[:50000], y_test[:50000], num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adjM8XKKuL0p","vscode":{"languageId":"python"}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"05 Prac. CNN.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
